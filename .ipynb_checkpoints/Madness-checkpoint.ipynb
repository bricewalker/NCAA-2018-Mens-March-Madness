{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 NCAA March Madness Men's Basketball Predictions\n",
    "\n",
    "### By Brice Walker\n",
    "\n",
    "[View on GitHub](https://github.com/bricewalker/Personal_Ames_Regression)\n",
    "\n",
    "[View on nbviewer](http://nbviewer.jupyter.org/github/bricewalker/Personal_Ames_Regression/blob/master/HousingRegression.ipynb)\n",
    "\n",
    "## Outline\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [Importing libraries](#libraries)\n",
    "- [Importing the dataset](#data)\n",
    "- [Exploratory analysis and plotting](#analysis)\n",
    "- [Feature extraction and engineering](#features)\n",
    "- [Classification analysis](#classification)\n",
    "    - [Logistic Regression](#log-reg)\n",
    "    - [KNeighbors](#knn)\n",
    "    - [Random Forest](#forest)\n",
    "    - [Extra Trees](#extra)\n",
    "    - [Support Vector Machine](#svm)\n",
    "    - [Gradient Boosting](#gradboost)\n",
    "    - [XGBoost](#xgboost)\n",
    "    - [LightGBM](#lgbm)\n",
    "    - [Keras/Tensorflow Neural Network](#nn)\n",
    "- [Ensembling models](#ensemble-reg)\n",
    "- [Exporting the final model](#exporting)\n",
    "\n",
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "This is a classification project completed for the 2018 March Madness Kaggle Competition. In this project, I have extracted 18 season-based, and 28 tournament-based team-level characteristics from several datasets. I used datasets provided by kaggle as well as data scraped from sports-reference.com. I then engineered several advanced measures and extracted Elo ratings. I used these characteristics to predict probabilities for each matchup in the 2018 March Madness Schedule. My final model was a soft voting classifier that used KNeighbors, Random Forest, Extra Trees, Logistic Regression, Gradient Boosting, and LightGBM classifiers to predict probabilities for each matchup. I also ran XGBoost and Keras/Tensorflow neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='libraries'></a>\n",
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Common imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from math import pi\n",
    "from math import sqrt\n",
    "import csv\n",
    "import urllib\n",
    "import pickle\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Math and descriptive stats\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy.special import boxcox1p, inv_boxcox1p\n",
    "\n",
    "# Sci-kit Learn modules for machine learning\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, log_loss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor, VotingClassifier\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier, RandomForestRegressor, RandomTreesEmbedding\n",
    "from sklearn.svm import SVR, LinearSVC, SVC, LinearSVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Boosting libraries\n",
    "import lightgbm as lgb\n",
    "import xgboost\n",
    "\n",
    "# Deep Learning modules\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Embedding, merge, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "K = 20.\n",
    "HOME_ADVANTAGE = 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "## Importing The Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_season_compact_pd = pd.read_csv('Data/KaggleData/RegularSeasonCompactResults.csv')\n",
    "seasons_pd = pd.read_csv('Data/KaggleData/Seasons.csv')\n",
    "teams_pd = pd.read_csv('Data/KaggleData/Teams.csv')\n",
    "tourney_compact_pd = pd.read_csv('Data/KaggleData/NCAATourneyCompactResults.csv')\n",
    "tourney_detailed_pd = pd.read_csv('Data/KaggleData/NCAATourneyDetailedResults.csv')\n",
    "conference_pd = pd.read_csv('Data/KaggleData/Conference.csv')\n",
    "tourney_results_pd = pd.read_csv('Data/KaggleData/TourneyResults.csv')\n",
    "sample_sub_pd = pd.read_csv('Data/KaggleData/sample_submission.csv')\n",
    "tourney_seeds_pd = pd.read_csv('Data/KaggleData/NCAATourneySeeds.csv')\n",
    "team_conferences_pd = pd.read_csv('Data/KaggleData/TeamConferences.csv')\n",
    "sample_sub_pd = pd.read_csv('Data/KaggleData/SampleSubmissionStage1.csv')\n",
    "seeds_pd = pd.read_csv('Data/KaggleData/NCAATourneySeeds.csv')\n",
    "elos_ratings_pd = pd.read_csv('Data/ElosRatings/season_elos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analysis'></a>\n",
    "## Exploratory analysis and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='features'></a>\n",
    "## Feature Engineering and Extraction\n",
    "\n",
    "This project attempts to predict outcomes of games based on the following team level characteristics for season games:\n",
    "- A modified Elo rating (where new entrants are initialized at a score of 1500, and there is no reversion to the mean between seasons)\n",
    "- Number of wins\n",
    "- Avg points per game scored\n",
    "- Avg points per game allowed\n",
    "- Avg # of 3 pointers per game\n",
    "- Avg turnovers per game\n",
    "- Avg Assists per game\n",
    "- Avg rebounds per game\n",
    "- Avg steals per game\n",
    "- Power 6 Conference\n",
    "- Reg Season championships\n",
    "- Strength of team's schedule\n",
    "- Championship appearances\n",
    "- Location of the game\n",
    "- A simple rating system\n",
    "\n",
    "And the following team level characteristics for tournament performance:<br>\n",
    "> Note: If a team plays in more than one tourney in a year than these values are averaged over all tourneys they played that year.\n",
    "\n",
    "- Tournament appearances\n",
    "- Conference tournament championships\n",
    "- Points scored for winning/losing team\n",
    "- A measure of possession\n",
    "- Offensive efficiency\n",
    "- Defensive efficiency\n",
    "- Net Rating (Offensive - Defensive efficiency)\n",
    "- Assist Ratio\n",
    "- Turnover Ratio\n",
    "- Shooting Percentage\n",
    "- Effective Field Goal Percentage adjusting for the fact that 3pt shots are more valuable\n",
    "- FTA Rating : How good a team is at drawing fouls.\n",
    "- Percentage of team offensive rebounds\n",
    "- Percentage of team defensive rebounds\n",
    "- Percentage of team total rebounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced tourney data\n",
    "df = pd.read_csv('Data/KaggleData/NCAATourneyDetailedResults.csv')\n",
    "# Points Winning/Losing Team\n",
    "df['WPts'] = df.apply(lambda row: 2*row.WFGM + row.WFGM3 + row.WFTM, axis=1)\n",
    "df['LPts'] = df.apply(lambda row: 2*row.LFGM + row.LFGM3 + row.LFTM, axis=1)\n",
    "# Calculate Winning/losing Team Possesion Feature\n",
    "wPos = df.apply(lambda row: 0.96*(row.WFGA + row.WTO + 0.44*row.WFTA - row.WOR), axis=1)\n",
    "df['WPos'] = df.apply(lambda row: 0.96*(row.WFGA + row.WTO + 0.44*row.WFTA - row.WOR), axis=1)\n",
    "lPos = df.apply(lambda row: 0.96*(row.LFGA + row.LTO + 0.44*row.LFTA - row.LOR), axis=1)\n",
    "df['LPos'] = lPos = df.apply(lambda row: 0.96*(row.LFGA + row.LTO + 0.44*row.LFTA - row.LOR), axis=1)\n",
    "df['Pos'] = (wPos+lPos)/2\n",
    "# Offensive efficiency (OffRtg) = 100 x (Points / Possessions)\n",
    "df['WOffRtg'] = df.apply(lambda row: 100 * (row.WPts / row.Pos), axis=1)\n",
    "df['LOffRtg'] = df.apply(lambda row: 100 * (row.LPts / row.Pos), axis=1)\n",
    "# Defensive efficiency (DefRtg) = 100 x (Opponent points / Opponent possessions)\n",
    "df['WDefRtg'] = df.LOffRtg\n",
    "df['LDefRtg'] = df.WOffRtg\n",
    "# Net Rating = Off.Rtg - Def.Rtg\n",
    "df['WNetRtg'] = df.apply(lambda row:(row.WOffRtg - row.WDefRtg), axis=1)\n",
    "df['LNetRtg'] = df.apply(lambda row:(row.LOffRtg - row.LDefRtg), axis=1)                       \n",
    "# Assist Ratio : Percentage of team possessions that end in assists\n",
    "df['WAstR'] = df.apply(lambda row: 100 * row.WAst / (row.WFGA + 0.44*row.WFTA + row.WAst + row.WTO), axis=1)\n",
    "df['LAstR'] = df.apply(lambda row: 100 * row.LAst / (row.LFGA + 0.44*row.LFTA + row.LAst + row.LTO), axis=1)\n",
    "# Turnover Ratio: Number of turnovers of a team per 100 possessions used.\n",
    "# (TO * 100) / (FGA + (FTA * 0.44) + AST + TO\n",
    "df['WTOR'] = df.apply(lambda row: 100 * row.LAst / (row.LFGA + 0.44*row.LFTA + row.LAst + row.LTO), axis=1)\n",
    "df['LTOR'] = df.apply(lambda row: 100 * row.LAst / (row.LFGA + 0.44*row.LFTA + row.LAst + row.LTO), axis=1)                  \n",
    "# The Shooting Percentage : Measure of Shooting Efficiency (FGA/FGA3, FTA)\n",
    "df['WTSP'] = df.apply(lambda row: 100 * row.WPts / (2 * (row.WFGA + 0.44 * row.WFTA)), axis=1)\n",
    "df['LTSP'] = df.apply(lambda row: 100 * row.LPts / (2 * (row.LFGA + 0.44 * row.LFTA)), axis=1)\n",
    "# eFG% : Effective Field Goal Percentage adjusting for the fact that 3pt shots are more valuable \n",
    "df['WeFGP'] = df.apply(lambda row:(row.WFGM + 0.5 * row.WFGM3) / row.WFGA, axis=1)      \n",
    "df['LeFGP'] = df.apply(lambda row:(row.LFGM + 0.5 * row.LFGM3) / row.LFGA, axis=1)   \n",
    "# FTA Rate : How good a team is at drawing fouls.\n",
    "df['WFTAR'] = df.apply(lambda row: row.WFTA / row.WFGA, axis=1)\n",
    "df['LFTAR'] = df.apply(lambda row: row.LFTA / row.LFGA, axis=1)                       \n",
    "# OREB% : Percentage of team offensive rebounds\n",
    "df['WORP'] = df.apply(lambda row: row.WOR / (row.WOR + row.LDR), axis=1)\n",
    "df['LORP'] = df.apply(lambda row: row.LOR / (row.LOR + row.WDR), axis=1)\n",
    "# DREB% : Percentage of team defensive rebounds\n",
    "df['WDRP'] = df.apply(lambda row: row.WDR / (row.WDR + row.LOR), axis=1)\n",
    "df['LDRP'] = df.apply(lambda row: row.LDR / (row.LDR + row.WOR), axis=1)                                      \n",
    "# REB% : Percentage of team total rebounds\n",
    "df['WRP'] = df.apply(lambda row: (row.WDR + row.WOR) / (row.WDR + row.WOR + row.LDR + row.LOR), axis=1)\n",
    "df['LRP'] = df.apply(lambda row: (row.LDR + row.WOR) / (row.WDR + row.WOR + row.LDR + row.LOR), axis=1) \n",
    "df['WPIE'] = df.apply(lambda row: (row.WDR + row.WOR) / (row.WDR + row.WOR + row.LDR + row.LOR), axis=1)\n",
    "wtmp = df.apply(lambda row: row.WPts + row.WFGM + row.WFTM - row.WFGA - row.WFTA + row.WDR + 0.5*row.WOR + row.WAst +row.WStl + 0.5*row.WBlk - row.WPF - row.WTO, axis=1)\n",
    "ltmp = df.apply(lambda row: row.LPts + row.LFGM + row.LFTM - row.LFGA - row.LFTA + row.LDR + 0.5*row.LOR + row.LAst +row.LStl + 0.5*row.LBlk - row.LPF - row.LTO, axis=1) \n",
    "df['WPIE'] = wtmp/(wtmp + ltmp)\n",
    "df['LPIE'] = ltmp/(wtmp + ltmp)\n",
    "    \n",
    "df.to_csv('Data/KaggleData/NCAATourneyDetailedResultsEnriched.csv', index=False)\n",
    "enriched_pd = pd.read_csv('Data/KaggleData/NCAATourneyDetailedResultsEnriched.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom Elo ratings. This takes a long time to run so beware!\n",
    "team_ids = set(reg_season_compact_pd.WTeamID).union(set(reg_season_compact_pd.LTeamID))\n",
    "\n",
    "elo_dict = dict(zip(list(team_ids), [1500] * len(team_ids)))\n",
    "\n",
    "reg_season_compact_pd['margin'] = reg_season_compact_pd.WScore - reg_season_compact_pd.LScore\n",
    "reg_season_compact_pd['w_elo'] = None\n",
    "reg_season_compact_pd['l_elo'] = None\n",
    "\n",
    "def elo_pred(elo1, elo2):\n",
    "    return(1. / (10. ** (-(elo1 - elo2) / 400.) + 1.))\n",
    "\n",
    "def expected_margin(elo_diff):\n",
    "    return((7.5 + 0.006 * elo_diff))\n",
    "\n",
    "def elo_update(w_elo, l_elo, margin):\n",
    "    elo_diff = w_elo - l_elo\n",
    "    pred = elo_pred(w_elo, l_elo)\n",
    "    mult = ((margin + 3.) ** 0.8) / expected_margin(elo_diff)\n",
    "    update = K * mult * (1 - pred)\n",
    "    return(pred, update)\n",
    "\n",
    "assert np.all(reg_season_compact_pd.index.values == np.array(range(reg_season_compact_pd.shape[0]))), \"Index is out of order.\"\n",
    "\n",
    "preds = []\n",
    "\n",
    "# Loop over all rows\n",
    "for i in range(reg_season_compact_pd.shape[0]):\n",
    "    \n",
    "    # Get key data from each row\n",
    "    w = reg_season_compact_pd.at[i, 'WTeamID']\n",
    "    l = reg_season_compact_pd.at[i, 'LTeamID']\n",
    "    margin = reg_season_compact_pd.at[i, 'margin']\n",
    "    wloc = reg_season_compact_pd.at[i, 'WLoc']\n",
    "    \n",
    "    # Home court advantage?\n",
    "    w_ad, l_ad, = 0., 0.\n",
    "    if wloc == \"H\":\n",
    "        w_ad += HOME_ADVANTAGE\n",
    "    elif wloc == \"A\":\n",
    "        l_ad += HOME_ADVANTAGE\n",
    "    \n",
    "    # Get elo updates as a result of each game\n",
    "    pred, update = elo_update(elo_dict[w] + w_ad,\n",
    "                              elo_dict[l] + l_ad, \n",
    "                              margin)\n",
    "    elo_dict[w] += update\n",
    "    elo_dict[l] -= update\n",
    "    preds.append(pred)\n",
    "\n",
    "    # Store elos in new dataframe\n",
    "    reg_season_compact_pd.loc[i, 'w_elo'] = elo_dict[w]\n",
    "    reg_season_compact_pd.loc[i, 'l_elo'] = elo_dict[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>margin</th>\n",
       "      <th>w_elo</th>\n",
       "      <th>l_elo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>20</td>\n",
       "      <td>1228</td>\n",
       "      <td>81</td>\n",
       "      <td>1328</td>\n",
       "      <td>64</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1514.65</td>\n",
       "      <td>1485.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1106</td>\n",
       "      <td>77</td>\n",
       "      <td>1354</td>\n",
       "      <td>70</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1505.61</td>\n",
       "      <td>1494.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1112</td>\n",
       "      <td>63</td>\n",
       "      <td>1223</td>\n",
       "      <td>56</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1505.61</td>\n",
       "      <td>1494.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1165</td>\n",
       "      <td>70</td>\n",
       "      <td>1432</td>\n",
       "      <td>54</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1509.37</td>\n",
       "      <td>1490.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1192</td>\n",
       "      <td>86</td>\n",
       "      <td>1447</td>\n",
       "      <td>74</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1507.76</td>\n",
       "      <td>1492.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  margin  \\\n",
       "0    1985      20     1228      81     1328      64    N      0      17   \n",
       "1    1985      25     1106      77     1354      70    H      0       7   \n",
       "2    1985      25     1112      63     1223      56    H      0       7   \n",
       "3    1985      25     1165      70     1432      54    H      0      16   \n",
       "4    1985      25     1192      86     1447      74    H      0      12   \n",
       "\n",
       "     w_elo    l_elo  \n",
       "0  1514.65  1485.35  \n",
       "1  1505.61  1494.39  \n",
       "2  1505.61  1494.39  \n",
       "3  1509.37  1490.63  \n",
       "4  1507.76  1492.24  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_season_compact_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>seed_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>1207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>1210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>1228</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>1260</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>1374</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  TeamID  seed_int\n",
       "0    1985    1207         1\n",
       "1    1985    1210         2\n",
       "2    1985    1228         3\n",
       "3    1985    1260         4\n",
       "4    1985    1374         5"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_to_int(seed):\n",
    "# Convert seeds to integers\n",
    "    s_int = int(seed[1:3])\n",
    "    return s_int\n",
    "seeds_pd['seed_int'] = seeds_pd.Seed.apply(seed_to_int)\n",
    "seeds_pd.drop(labels=['Seed'], inplace=True, axis=1) # This is the string label\n",
    "seeds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamList = teams_pd['TeamName'].tolist()\n",
    "NCAAChampionsList = tourney_results_pd['NCAA Champion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Power6Conf(team_id):\n",
    "    team_pd = team_conferences_pd[(team_conferences_pd['Season'] == 2018) & (team_conferences_pd['TeamID'] == team_id)]\n",
    "    if (len(team_pd) == 0):\n",
    "        return 0\n",
    "    confName = team_pd.iloc[0]['ConfAbbrev']\n",
    "    return int(confName == 'sec' or confName == 'acc'or confName == 'big_ten' or confName == 'big_twelve' or confName == 'big_east' or confName == 'pac_twelve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTeamName(team_id):\n",
    "    return teams_pd[teams_pd['TeamID'] == team_id].values[0][1]\n",
    "\n",
    "def findNumChampionships(team_id):\n",
    "    name = createTeamName(team_id)\n",
    "    return NCAAChampionsList.count(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleCases(arr):\n",
    "    indices = []\n",
    "    listLen = len(arr)\n",
    "    for i in range(listLen):\n",
    "        if (arr[i] == 'St' or arr[i] == 'FL'):\n",
    "            indices.append(i)\n",
    "    for p in indices:\n",
    "        arr[p-1] = arr[p-1] + ' ' + arr[p]\n",
    "    for i in range(len(indices)): \n",
    "        arr.remove(arr[indices[i] - i])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkConferenceChamp(team_id, year):\n",
    "    year_conf_pd = conference_pd[conference_pd['Year'] == year]\n",
    "    champs = year_conf_pd['Regular Season Champ'].tolist()\n",
    "# In case of a tie\n",
    "    champs_separated = [words for segments in champs for words in segments.split()]\n",
    "    name = createTeamName(team_id)\n",
    "    champs_separated = handleCases(champs_separated)\n",
    "    if (name in champs_separated):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkConferenceTourneyChamp(team_id, year):\n",
    "    year_conf_pd = conference_pd[conference_pd['Year'] == year]\n",
    "    champs = year_conf_pd['Tournament Champ'].tolist()\n",
    "    name = createTeamName(team_id)\n",
    "    if (name in champs):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTourneyAppearances(team_id):\n",
    "    return len(tourney_seeds_pd[tourney_seeds_pd['TeamID'] == team_id].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing names in csv's with differing formats\n",
    "def handleDifferentCSV(df):\n",
    "    df['School'] = df['School'].replace('(State)', 'St', regex=True) \n",
    "    df['School'] = df['School'].replace('Albany (NY)', 'Albany NY') \n",
    "    df['School'] = df['School'].replace('Boston University', 'Boston Univ')\n",
    "    df['School'] = df['School'].replace('Central Michigan', 'C Michigan')\n",
    "    df['School'] = df['School'].replace('(Eastern)', 'E', regex=True)\n",
    "    df['School'] = df['School'].replace('Louisiana St', 'LSU')\n",
    "    df['School'] = df['School'].replace('North Carolina St', 'NC State')\n",
    "    df['School'] = df['School'].replace('Southern California', 'USC')\n",
    "    df['School'] = df['School'].replace('University of California', 'California', regex=True) \n",
    "    df['School'] = df['School'].replace('American', 'American Univ')\n",
    "    df['School'] = df['School'].replace('Arkansas-Little Rock', 'Ark Little Rock')\n",
    "    df['School'] = df['School'].replace('Arkansas-Pine Bluff', 'Ark Pine Bluff')\n",
    "    df['School'] = df['School'].replace('Bowling Green St', 'Bowling Green')\n",
    "    df['School'] = df['School'].replace('Brigham Young', 'BYU')\n",
    "    df['School'] = df['School'].replace('Cal Poly', 'Cal Poly SLO')\n",
    "    df['School'] = df['School'].replace('Centenary (LA)', 'Centenary')\n",
    "    df['School'] = df['School'].replace('Central Connecticut St', 'Central Conn')\n",
    "    df['School'] = df['School'].replace('Charleston Southern', 'Charleston So')\n",
    "    df['School'] = df['School'].replace('Coastal Carolina', 'Coastal Car')\n",
    "    df['School'] = df['School'].replace('College of Charleston', 'Col Charleston')\n",
    "    df['School'] = df['School'].replace('Cal St Fullerton', 'CS Fullerton')\n",
    "    df['School'] = df['School'].replace('Cal St Sacramento', 'CS Sacramento')\n",
    "    df['School'] = df['School'].replace('Cal St Bakersfield', 'CS Bakersfield')\n",
    "    df['School'] = df['School'].replace('Cal St Northridge', 'CS Northridge')\n",
    "    df['School'] = df['School'].replace('East Tennessee St', 'ETSU')\n",
    "    df['School'] = df['School'].replace('Detroit Mercy', 'Detroit')\n",
    "    df['School'] = df['School'].replace('Fairleigh Dickinson', 'F Dickinson')\n",
    "    df['School'] = df['School'].replace('Florida Atlantic', 'FL Atlantic')\n",
    "    df['School'] = df['School'].replace('Florida Gulf Coast', 'FL Gulf Coast')\n",
    "    df['School'] = df['School'].replace('Florida International', 'Florida Intl')\n",
    "    df['School'] = df['School'].replace('George Washington', 'G Washington')\n",
    "    df['School'] = df['School'].replace('Georgia Southern', 'Ga Southern')\n",
    "    df['School'] = df['School'].replace('Gardner-Webb', 'Gardner Webb')\n",
    "    df['School'] = df['School'].replace('Illinois-Chicago', 'IL Chicago')\n",
    "    df['School'] = df['School'].replace('Kent St', 'Kent')\n",
    "    df['School'] = df['School'].replace('Long Island University', 'Long Island')\n",
    "    df['School'] = df['School'].replace('Loyola Marymount', 'Loy Marymount')\n",
    "    df['School'] = df['School'].replace('Loyola (MD)', 'Loyola MD')\n",
    "    df['School'] = df['School'].replace('Loyola (IL)', 'Loyola-Chicago')\n",
    "    df['School'] = df['School'].replace('Massachusetts', 'MA Lowell')\n",
    "    df['School'] = df['School'].replace('Maryland-Eastern Shore', 'MD E Shore')\n",
    "    df['School'] = df['School'].replace('Miami (FL)', 'Miami FL')\n",
    "    df['School'] = df['School'].replace('Miami (OH)', 'Miami OH')\n",
    "    df['School'] = df['School'].replace('Missouri-Kansas City', 'Missouri KC')\n",
    "    df['School'] = df['School'].replace('Monmouth', 'Monmouth NJ')\n",
    "    df['School'] = df['School'].replace('Mississippi Valley St', 'MS Valley St')\n",
    "    df['School'] = df['School'].replace('Montana St', 'MTSU')\n",
    "    df['School'] = df['School'].replace('Northern Colorado', 'N Colorado')\n",
    "    df['School'] = df['School'].replace('North Dakota St', 'N Dakota St')\n",
    "    df['School'] = df['School'].replace('Northern Illinois', 'N Illinois')\n",
    "    df['School'] = df['School'].replace('Northern Kentucky', 'N Kentucky')\n",
    "    df['School'] = df['School'].replace('North Carolina A&T', 'NC A&T')\n",
    "    df['School'] = df['School'].replace('North Carolina Central', 'NC Central')\n",
    "    df['School'] = df['School'].replace('Pennsylvania', 'Penn')\n",
    "    df['School'] = df['School'].replace('South Carolina St', 'S Carolina St')\n",
    "    df['School'] = df['School'].replace('Southern Illinois', 'S Illinois')\n",
    "    df['School'] = df['School'].replace('UC-Santa Barbara', 'Santa Barbara')\n",
    "    df['School'] = df['School'].replace('Southeastern Louisiana', 'SE Louisiana')\n",
    "    df['School'] = df['School'].replace('Southeast Missouri St', 'SE Missouri St')\n",
    "    df['School'] = df['School'].replace('Stephen F. Austin', 'SF Austin')\n",
    "    df['School'] = df['School'].replace('Southern Methodist', 'SMU')\n",
    "    df['School'] = df['School'].replace('Southern Mississippi', 'Southern Miss')\n",
    "    df['School'] = df['School'].replace('Southern', 'Southern Univ')\n",
    "    df['School'] = df['School'].replace('St. Bonaventure', 'St Bonaventure')\n",
    "    df['School'] = df['School'].replace('St. Francis (NY)', 'St Francis NY')\n",
    "    df['School'] = df['School'].replace('Saint Francis (PA)', 'St Francis PA')\n",
    "    df['School'] = df['School'].replace('St. John\\'s (NY)', 'St John\\'s')\n",
    "    df['School'] = df['School'].replace('Saint Joseph\\'s', 'St Joseph\\'s PA')\n",
    "    df['School'] = df['School'].replace('Saint Louis', 'St Louis')\n",
    "    df['School'] = df['School'].replace('Saint Mary\\'s (CA)', 'St Mary\\'s CA')\n",
    "    df['School'] = df['School'].replace('Mount Saint Mary\\'s', 'Mt St Mary\\'s')\n",
    "    df['School'] = df['School'].replace('Saint Peter\\'s', 'St Peter\\'s')\n",
    "    df['School'] = df['School'].replace('Texas A&M-Corpus Christian', 'TAM C. Christian')\n",
    "    df['School'] = df['School'].replace('Texas Christian', 'TCU')\n",
    "    df['School'] = df['School'].replace('Tennessee-Martin', 'TN Martin')\n",
    "    df['School'] = df['School'].replace('Texas-Rio Grande Valley', 'UTRGV')\n",
    "    df['School'] = df['School'].replace('Texas Southern', 'TX Southern')\n",
    "    df['School'] = df['School'].replace('Alabama-Birmingham', 'UAB')\n",
    "    df['School'] = df['School'].replace('UC-Davis', 'UC Davis')\n",
    "    df['School'] = df['School'].replace('UC-Irvine', 'UC Irvine')\n",
    "    df['School'] = df['School'].replace('UC-Riverside', 'UC Riverside')\n",
    "    df['School'] = df['School'].replace('Central Florida', 'UCF')\n",
    "    df['School'] = df['School'].replace('Louisiana-Lafayette', 'ULL')\n",
    "    df['School'] = df['School'].replace('Louisiana-Monroe', 'ULM')\n",
    "    df['School'] = df['School'].replace('Maryland-Baltimore County', 'UMBC')\n",
    "    df['School'] = df['School'].replace('North Carolina-Asheville', 'UNC Asheville')\n",
    "    df['School'] = df['School'].replace('North Carolina-Greensboro', 'UNC Greensboro')\n",
    "    df['School'] = df['School'].replace('North Carolina-Wilmington', 'UNC Wilmington')\n",
    "    df['School'] = df['School'].replace('Nevada-Las Vegas', 'UNLV')\n",
    "    df['School'] = df['School'].replace('Texas-Arlington', 'UT Arlington')\n",
    "    df['School'] = df['School'].replace('Texas-San Antonio', 'UT San Antonio')\n",
    "    df['School'] = df['School'].replace('Texas-El Paso', 'UTEP')\n",
    "    df['School'] = df['School'].replace('Virginia Commonwealth', 'VA Commonwealth')\n",
    "    df['School'] = df['School'].replace('Western Carolina', 'W Carolina')\n",
    "    df['School'] = df['School'].replace('Western Illinois', 'W Illinois')\n",
    "    df['School'] = df['School'].replace('Western Kentucky', 'WKU')\n",
    "    df['School'] = df['School'].replace('Western Michigan', 'W Michigan')\n",
    "    df['School'] = df['School'].replace('Abilene Christian', 'Abilene Chr')\n",
    "    df['School'] = df['School'].replace('Montana State', 'Montana St')\n",
    "    df['School'] = df['School'].replace('Central Arkansas', 'Cent Arkansas')\n",
    "    df['School'] = df['School'].replace('Houston Baptist', 'Houston Bap')\n",
    "    df['School'] = df['School'].replace('South Dakota St', 'S Dakota St')\n",
    "    df['School'] = df['School'].replace('Maryland-Eastern Shore', 'MD E Shore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHomeStat(row):\n",
    "    if (row == 'H'):\n",
    "        home = 1\n",
    "    if (row == 'A'):\n",
    "        home = -1\n",
    "    if (row == 'N'):\n",
    "        home = 0\n",
    "    return home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeInput(arr):\n",
    "    for i in range(arr.shape[1]):\n",
    "        minVal = min(arr[:,i])\n",
    "        maxVal = max(arr[:,i])\n",
    "        arr[:,i] =  (arr[:,i] - minVal) / (maxVal - minVal)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeInput2(X):\n",
    "    return (X - np.mean(X, axis = 0)) / np.std(X, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSeasonTourneyData(team_id, year):\n",
    "    year_data_pd = reg_season_compact_pd[reg_season_compact_pd['Season'] == year]\n",
    "# Elo   \n",
    "    year_pd = year_data_pd.copy()\n",
    "    year_pd = year_pd.loc[(year_pd.WTeamID == team_id) | (year_pd.LTeamID == team_id), :]\n",
    "    year_pd.sort_values(['Season', 'DayNum'], inplace=True)\n",
    "    year_pd.drop_duplicates(['Season'], keep='last', inplace=True)\n",
    "    w_mask = year_pd.WTeamID == team_id\n",
    "    l_mask = year_pd.LTeamID == team_id\n",
    "    year_pd['season_elo'] = None\n",
    "    year_pd.loc[w_mask, 'season_elo'] = year_pd.loc[w_mask, 'w_elo']\n",
    "    year_pd.loc[l_mask, 'season_elo'] = year_pd.loc[l_mask, 'l_elo']\n",
    "    elo = year_pd.season_elo\n",
    "    elo = elo.values.mean()\n",
    "# Points per game\n",
    "    gamesWon = year_data_pd[year_data_pd.WTeamID == team_id] \n",
    "    totalPointsScored = gamesWon['WScore'].sum()\n",
    "    gamesLost = year_data_pd[year_data_pd.LTeamID == team_id] \n",
    "    totalGames = gamesWon.append(gamesLost)\n",
    "    numGames = len(totalGames.index)\n",
    "    totalPointsScored += gamesLost['LScore'].sum()\n",
    "# Number of points allowed\n",
    "    totalPointsAllowed = gamesWon['LScore'].sum()\n",
    "    totalPointsAllowed += gamesLost['WScore'].sum()\n",
    "# Scraped data    \n",
    "    stats_SOS_pd = pd.read_csv('Data/RegSeasonStats/MMStats_'+str(year)+'.csv')\n",
    "    stats_SOS_pd = handleDifferentCSV(stats_SOS_pd)\n",
    "    ratings_pd = pd.read_csv('Data/RatingStats/RatingStats_'+str(year)+'.csv')\n",
    "    ratings_pd = handleDifferentCSV(ratings_pd)\n",
    "    \n",
    "    name = createTeamName(team_id)\n",
    "    team = stats_SOS_pd[stats_SOS_pd['School'] == name]\n",
    "    team_rating = ratings_pd[ratings_pd['School'] == name]\n",
    "    if (len(team.index) == 0 or len(team_rating.index) == 0):\n",
    "        total3sMade = 0\n",
    "        totalTurnovers = 0\n",
    "        totalAssists = 0\n",
    "        sos = 0\n",
    "        totalRebounds = 0\n",
    "        srs = 0\n",
    "        totalSteals = 0\n",
    "    else:\n",
    "        total3sMade = team['X3P'].values[0]\n",
    "        totalTurnovers = team['TOV'].values[0]\n",
    "        if (math.isnan(totalTurnovers)):\n",
    "            totalTurnovers = 0\n",
    "        totalAssists = team['AST'].values[0]\n",
    "        if (math.isnan(totalAssists)):\n",
    "            totalAssists = 0\n",
    "        sos = team['SOS'].values[0]\n",
    "        srs = team['SRS'].values[0]\n",
    "        totalRebounds = team['TRB'].values[0]\n",
    "        if (math.isnan(totalRebounds)):\n",
    "            totalRebounds = 0\n",
    "        totalSteals = team['STL'].values[0]\n",
    "        if (math.isnan(totalSteals)):\n",
    "            totalSteals = 0\n",
    "    \n",
    "# Finding tourney seed\n",
    "    tourneyYear = tourney_seeds_pd[tourney_seeds_pd['Season'] == year]\n",
    "    seed = tourneyYear[tourneyYear['TeamID'] == team_id]\n",
    "    if (len(seed.index) != 0):\n",
    "        seed = seed.values[0][1]\n",
    "        tournamentSeed = int(seed[1:3])\n",
    "    else:\n",
    "        tournamentSeed = 25\n",
    "\n",
    "# Number of wins and losses\n",
    "    numWins = len(gamesWon.index)\n",
    "# Preventing division by 0\n",
    "    if numGames == 0:\n",
    "        avgPointsScored = 0\n",
    "        avgPointsAllowed = 0\n",
    "        avg3sMade = 0\n",
    "        avgTurnovers = 0\n",
    "        avgAssists = 0\n",
    "        avgRebounds = 0\n",
    "        avgSteals = 0\n",
    "    else:\n",
    "        avgPointsScored = totalPointsScored/numGames\n",
    "        avgPointsAllowed = totalPointsAllowed/numGames\n",
    "        avg3sMade = total3sMade/numGames\n",
    "        avgTurnovers = totalTurnovers/numGames\n",
    "        avgAssists = totalAssists/numGames\n",
    "        avgRebounds = totalRebounds/numGames\n",
    "        avgSteals = totalSteals/numGames\n",
    "        \n",
    "# Tourney data   \n",
    "    enriched_df = enriched_pd[enriched_pd['Season'] == year]\n",
    "    enriched_df = enriched_df.loc[(enriched_df.WTeamID == team_id) | (enriched_df.LTeamID == team_id), :]\n",
    "    w_mask = enriched_df.WTeamID == team_id\n",
    "    l_mask = enriched_df.LTeamID == team_id\n",
    "    enriched_df['Score'] = 0\n",
    "    enriched_df['FGM'] = 0\n",
    "    enriched_df['FGA'] = 0\n",
    "    enriched_df['FGM3'] = 0\n",
    "    enriched_df['FGA3'] = 0\n",
    "    enriched_df['FTM'] = 0\n",
    "    enriched_df['FTA'] = 0\n",
    "    enriched_df['OR'] = 0\n",
    "    enriched_df['DR'] = 0\n",
    "    enriched_df['Ast'] = 0\n",
    "    enriched_df['TO'] = 0\n",
    "    enriched_df['Stl'] = 0\n",
    "    enriched_df['Blk'] = 0\n",
    "    enriched_df['PF'] = 0\n",
    "    enriched_df['Pts'] = 0\n",
    "    enriched_df['Pos'] = 0\n",
    "    enriched_df['OffRtg'] = 0\n",
    "    enriched_df['DefRtg'] = 0\n",
    "    enriched_df['NetRtg'] = 0\n",
    "    enriched_df['AstR'] = 0\n",
    "    enriched_df['TOR'] = 0\n",
    "    enriched_df['TSP'] = 0\n",
    "    enriched_df['eFGP'] = 0\n",
    "    enriched_df['FTAR'] = 0\n",
    "    enriched_df['ORP'] = 0\n",
    "    enriched_df['DRP'] = 0\n",
    "    enriched_df['RP'] = 0\n",
    "    enriched_df['PIE'] = 0\n",
    "    enriched_df.loc[w_mask, 'Score'] = enriched_df.loc[w_mask, 'WScore']\n",
    "    enriched_df.loc[l_mask, 'Score'] = enriched_df.loc[l_mask, 'LScore']\n",
    "    Score = enriched_df.Score.values.mean()\n",
    "    enriched_df.loc[w_mask, 'FGM'] = enriched_df.loc[w_mask, 'WFGM']\n",
    "    enriched_df.loc[l_mask, 'FGM'] = enriched_df.loc[l_mask, 'LFGM']\n",
    "    FGM = enriched_df.FGM.values.mean()\n",
    "    enriched_df.loc[w_mask, 'FGA'] = enriched_df.loc[w_mask, 'WFGA']\n",
    "    enriched_df.loc[l_mask, 'FGA'] = enriched_df.loc[l_mask, 'LFGA']\n",
    "    FGA = enriched_df.FGA.values.mean()\n",
    "    enriched_df.loc[w_mask, 'FGM3'] = enriched_df.loc[w_mask, 'WFGM3']\n",
    "    enriched_df.loc[l_mask, 'FGM3'] = enriched_df.loc[l_mask, 'LFGM3']\n",
    "    FGM3 = enriched_df.FGM3.values.mean()\n",
    "    enriched_df.loc[w_mask, 'FGA3'] = enriched_df.loc[w_mask, 'WFGA3']\n",
    "    enriched_df.loc[l_mask, 'FGA3'] = enriched_df.loc[l_mask, 'LFGA3']\n",
    "    FGA3 = enriched_df.FGA3.values.mean()\n",
    "    enriched_df.loc[w_mask, 'FTM'] = enriched_df.loc[w_mask, 'WFTM']\n",
    "    enriched_df.loc[l_mask, 'FTM'] = enriched_df.loc[l_mask, 'LFTM']\n",
    "    FTM = enriched_df.FTM.values.mean()\n",
    "    enriched_df.loc[w_mask, 'FTA'] = enriched_df.loc[w_mask, 'WFTA']\n",
    "    enriched_df.loc[l_mask, 'FTA'] = enriched_df.loc[l_mask, 'LFTA']\n",
    "    FTA = enriched_df.FTA.values.mean()\n",
    "    enriched_df.loc[w_mask, 'OR'] = enriched_df.loc[w_mask, 'WOR']\n",
    "    enriched_df.loc[l_mask, 'OR'] = enriched_df.loc[l_mask, 'LOR']\n",
    "    OR = enriched_df.OR.values.mean()\n",
    "    enriched_df.loc[w_mask, 'DR'] = enriched_df.loc[w_mask, 'WDR']\n",
    "    enriched_df.loc[l_mask, 'DR'] = enriched_df.loc[l_mask, 'LDR']\n",
    "    DR = enriched_df.DR.values.mean()\n",
    "    enriched_df.loc[w_mask, 'Ast'] = enriched_df.loc[w_mask, 'WAst']\n",
    "    enriched_df.loc[l_mask, 'Ast'] = enriched_df.loc[l_mask, 'LAst']\n",
    "    Ast = enriched_df.Ast.values.mean()\n",
    "    enriched_df.loc[w_mask, 'TO'] = enriched_df.loc[w_mask, 'WTO']\n",
    "    enriched_df.loc[l_mask, 'TO'] = enriched_df.loc[l_mask, 'LTO']\n",
    "    TO = enriched_df.TO.values.mean()\n",
    "    enriched_df.loc[w_mask, 'Stl'] = enriched_df.loc[w_mask, 'WStl']\n",
    "    enriched_df.loc[l_mask, 'Stl'] = enriched_df.loc[l_mask, 'LStl']\n",
    "    Stl = enriched_df.Stl.values.mean()\n",
    "    enriched_df.loc[w_mask, 'Blk'] = enriched_df.loc[w_mask, 'WBlk']\n",
    "    enriched_df.loc[l_mask, 'Blk'] = enriched_df.loc[l_mask, 'LBlk']\n",
    "    Blk = enriched_df.Blk.values.mean()\n",
    "    enriched_df.loc[w_mask, 'PF'] = enriched_df.loc[w_mask, 'WPF']\n",
    "    enriched_df.loc[l_mask, 'PF'] = enriched_df.loc[l_mask, 'LPF']\n",
    "    PF = enriched_df.PF.values.mean()\n",
    "    enriched_df.loc[w_mask, 'Pts'] = enriched_df.loc[w_mask, 'WPts']\n",
    "    enriched_df.loc[l_mask, 'Pts'] = enriched_df.loc[l_mask, 'LPts']\n",
    "    Pts = enriched_df.Pts.values.mean()\n",
    "    enriched_df.loc[w_mask, 'Pos'] = enriched_df.loc[w_mask, 'WPos']\n",
    "    enriched_df.loc[l_mask, 'Pos'] = enriched_df.loc[l_mask, 'LPos']\n",
    "    Pos = enriched_df.Pos.values.mean()\n",
    "    enriched_df.loc[w_mask, 'OffRtg'] = enriched_df.loc[w_mask, 'WOffRtg']\n",
    "    enriched_df.loc[l_mask, 'OffRtg'] = enriched_df.loc[l_mask, 'LOffRtg']\n",
    "    OffRtg = enriched_df.OffRtg.values.mean()\n",
    "    enriched_df.loc[w_mask, 'DefRtg'] = enriched_df.loc[w_mask, 'WDefRtg']\n",
    "    enriched_df.loc[l_mask, 'DefRtg'] = enriched_df.loc[l_mask, 'LDefRtg']\n",
    "    DefRtg = enriched_df.DefRtg.values.mean()\n",
    "    enriched_df.loc[w_mask, 'NetRtg'] = enriched_df.loc[w_mask, 'WNetRtg']\n",
    "    enriched_df.loc[l_mask, 'NetRtg'] = enriched_df.loc[l_mask, 'LNetRtg']\n",
    "    NetRtg = enriched_df.NetRtg.values.mean()\n",
    "    enriched_df.loc[w_mask, 'AstR'] = enriched_df.loc[w_mask, 'WAstR']\n",
    "    enriched_df.loc[l_mask, 'AstR'] = enriched_df.loc[l_mask, 'LAstR']\n",
    "    AstR = enriched_df.AstR.values.mean()\n",
    "    enriched_df.loc[w_mask, 'TOR'] = enriched_df.loc[w_mask, 'WTOR']\n",
    "    enriched_df.loc[l_mask, 'TOR'] = enriched_df.loc[l_mask, 'LTOR']\n",
    "    TOR = enriched_df.TOR.values.mean()\n",
    "    enriched_df.loc[w_mask, 'TSP'] = enriched_df.loc[w_mask, 'WTSP']\n",
    "    enriched_df.loc[l_mask, 'TSP'] = enriched_df.loc[l_mask, 'LTSP']\n",
    "    TSP = enriched_df.TSP.values.mean()\n",
    "    enriched_df.loc[w_mask, 'eFGP'] = enriched_df.loc[w_mask, 'WeFGP']\n",
    "    enriched_df.loc[l_mask, 'eFGP'] = enriched_df.loc[l_mask, 'LeFGP']\n",
    "    eFGP = enriched_df.eFGP.values.mean()\n",
    "    enriched_df.loc[w_mask, 'FTAR'] = enriched_df.loc[w_mask, 'WFTAR']\n",
    "    enriched_df.loc[l_mask, 'FTAR'] = enriched_df.loc[l_mask, 'LFTAR']\n",
    "    FTAR = enriched_df.FTAR.values.mean()\n",
    "    enriched_df.loc[w_mask, 'ORP'] = enriched_df.loc[w_mask, 'WORP']\n",
    "    enriched_df.loc[l_mask, 'ORP'] = enriched_df.loc[l_mask, 'LORP']\n",
    "    ORP = enriched_df.ORP.values.mean()\n",
    "    enriched_df.loc[w_mask, 'DRP'] = enriched_df.loc[w_mask, 'WDRP']\n",
    "    enriched_df.loc[l_mask, 'DRP'] = enriched_df.loc[l_mask, 'LDRP']\n",
    "    DRP = enriched_df.DRP.values.mean()\n",
    "    enriched_df.loc[w_mask, 'RP'] = enriched_df.loc[w_mask, 'WRP']\n",
    "    enriched_df.loc[l_mask, 'RP'] = enriched_df.loc[l_mask, 'LRP']\n",
    "    RP = enriched_df.RP.values.mean()\n",
    "    enriched_df.loc[w_mask, 'PIE'] = enriched_df.loc[w_mask, 'WPIE']\n",
    "    enriched_df.loc[l_mask, 'PIE'] = enriched_df.loc[l_mask, 'LPIE']\n",
    "    PIE = enriched_df.PIE.values.mean()\n",
    "    \n",
    "    return [numWins, avgPointsScored, avgPointsAllowed, Power6Conf(team_id), avg3sMade, avgAssists, avgTurnovers,\n",
    "            checkConferenceChamp(team_id, year), checkConferenceTourneyChamp(team_id, year), tournamentSeed,\n",
    "            sos, srs, avgRebounds, avgSteals, getTourneyAppearances(team_id), findNumChampionships(team_id), elo,\n",
    "            FGM, FGA, FGM3, FGA3, FTM, FTA, OR, DR, Ast, TO, Stl, Blk, PF, Pts, Pos, OffRtg, DefRtg, NetRtg, Score,\n",
    "            AstR, TOR, TSP, eFGP, FTAR, ORP, DRP, RP, PIE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareTwoTeams(id_1, id_2, year):\n",
    "    team_1 = getSeasonTourneyData(id_1, year)\n",
    "    team_2 = getSeasonTourneyData(id_2, year)\n",
    "    diff = [a - b for a, b in zip(team_1, team_2)]\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSeasonDict(year):\n",
    "    seasonDictionary = collections.defaultdict(list)\n",
    "    for team in teamList:\n",
    "        team_id = teams_pd[teams_pd['TeamName'] == team].values[0][0]\n",
    "        team_vector = getSeasonTourneyData(team_id, year)\n",
    "        seasonDictionary[team_id] = team_vector\n",
    "    return seasonDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainingSet(years, stage1Years):\n",
    "    totalNumGames = 0\n",
    "    for year in years:\n",
    "        season = reg_season_compact_pd[reg_season_compact_pd['Season'] == year]\n",
    "        totalNumGames += len(season.index)\n",
    "        tourney = tourney_compact_pd[tourney_compact_pd['Season'] == year]\n",
    "        totalNumGames += len(tourney.index)\n",
    "    numFeatures = len(getSeasonTourneyData(1181,2012))\n",
    "    X_train = np.zeros(( totalNumGames, numFeatures + 1))\n",
    "    y_train = np.zeros(( totalNumGames ))\n",
    "    indexCounter = 0\n",
    "    for year in years:\n",
    "        team_vectors = createSeasonDict(year)\n",
    "        season = reg_season_compact_pd[reg_season_compact_pd['Season'] == year]\n",
    "        numGamesInSeason = len(season.index)\n",
    "        tourney = tourney_compact_pd[tourney_compact_pd['Season'] == year]\n",
    "        numGamesInSeason += len(tourney.index)\n",
    "        xTrainSeason = np.zeros(( numGamesInSeason, numFeatures + 1))\n",
    "        yTrainSeason = np.zeros(( numGamesInSeason ))\n",
    "        counter = 0\n",
    "        for index, row in season.iterrows():\n",
    "            w_team = row['WTeamID']\n",
    "            w_vector = team_vectors[w_team]\n",
    "            l_team = row['LTeamID']\n",
    "            l_vector = team_vectors[l_team]\n",
    "            diff = [a - b for a, b in zip(w_vector, l_vector)]\n",
    "            home = createHomeStat(row['WLoc'])\n",
    "            if (counter % 2 == 0):\n",
    "                diff.append(home) \n",
    "                xTrainSeason[counter] = diff\n",
    "                yTrainSeason[counter] = 1\n",
    "            else:\n",
    "                diff.append(-home)\n",
    "                xTrainSeason[counter] = [ -p for p in diff]\n",
    "                yTrainSeason[counter] = 0\n",
    "            counter += 1\n",
    "        for index, row in tourney.iterrows():\n",
    "            w_team = row['WTeamID']\n",
    "            w_vector = team_vectors[w_team]\n",
    "            l_team = row['LTeamID']\n",
    "            l_vector = team_vectors[l_team]\n",
    "            diff = [a - b for a, b in zip(w_vector, l_vector)]\n",
    "            home = 0\n",
    "            if (counter % 2 == 0):\n",
    "                diff.append(home) \n",
    "                xTrainSeason[counter] = diff\n",
    "                yTrainSeason[counter] = 1\n",
    "            else:\n",
    "                diff.append(-home)\n",
    "                xTrainSeason[counter] = [ -p for p in diff]\n",
    "                yTrainSeason[counter] = 0\n",
    "            counter += 1\n",
    "        X_train[indexCounter:numGamesInSeason+indexCounter] = xTrainSeason\n",
    "        y_train[indexCounter:numGamesInSeason+indexCounter] = yTrainSeason\n",
    "        indexCounter += numGamesInSeason\n",
    "        print ('Finished year:', year)\n",
    "        if (year in stage1Years):\n",
    "            np.save('Data/PrecomputedMatrices/TeamVectors/' + str(year) + 'TeamVectors', team_vectors)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndSave(years, stage1Years):\n",
    "    X_train, y_train = createTrainingSet(years, stage1Years)\n",
    "    np.save('Data/PrecomputedMatrices/X_train', X_train)\n",
    "    np.save('Data/PrecomputedMatrices/y_train', y_train)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: Mean of empty slice.\n",
      "  \n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:123: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:126: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:129: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:132: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:135: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:141: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:144: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:147: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:150: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:153: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:156: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:159: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:162: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:165: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:171: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:174: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:177: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:180: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:183: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:186: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:189: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:192: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:195: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:198: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:201: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:204: RuntimeWarning: Mean of empty slice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished year: 1994\n",
      "Finished year: 1995\n",
      "Finished year: 1996\n",
      "Finished year: 1997\n",
      "Finished year: 1998\n",
      "Finished year: 1999\n",
      "Finished year: 2000\n",
      "Finished year: 2001\n",
      "Finished year: 2002\n",
      "Finished year: 2003\n",
      "Finished year: 2004\n",
      "Finished year: 2005\n",
      "Finished year: 2006\n",
      "Finished year: 2007\n",
      "Finished year: 2008\n",
      "Finished year: 2009\n",
      "Finished year: 2010\n",
      "Finished year: 2011\n",
      "Finished year: 2012\n",
      "Finished year: 2013\n",
      "Finished year: 2014\n",
      "Finished year: 2015\n",
      "Finished year: 2016\n",
      "Finished year: 2017\n"
     ]
    }
   ],
   "source": [
    "years = range(1994,2018)\n",
    "# Saves the team vectors for the following years\n",
    "stage1Years = range(2014,2018)\n",
    "if os.path.exists(\"Data/PrecomputedMatrices/X_train.npy\") and os.path.exists(\"Data/PrecomputedMatrices/y_train.npy\"):\n",
    "    print ('There are already precomputed X_train, and y_train matricies.')\n",
    "#    os.remove(\"Data/PrecomputedMatrices/X_train.npy\")\n",
    "#    os.remove(\"Data/PrecomputedMatrices/y_train.npy\")\n",
    "#    createAndSave(years, stage1Years)\n",
    "else:\n",
    "    createAndSave(years, stage1Years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (116530, 46)\n",
      "Shape of y_train: (116530,)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = np.load(\"Data/PrecomputedMatrices/X_train.npy\")\n",
    "ytrain = np.load(\"Data/PrecomputedMatrices/y_train.npy\")\n",
    "print (\"Shape of X_train:\", Xtrain.shape)\n",
    "print (\"Shape of y_train:\", ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.nan_to_num(Xtrain)\n",
    "ytrain = np.nan_to_num(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classification'></a>\n",
    "## Classification Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='log-reg'></a>\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=95, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression(random_state=95)\n",
    "log.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='knn'></a>\n",
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.6min remaining:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'kd_tree', 'leaf_size': 18, 'n_neighbors': 60, 'p': 1, 'weights': 'uniform'}\n",
      "0.751181390666\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=18, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=60, p=1,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "              'n_neighbors': [60],\n",
    "              'weights': ['uniform'],\n",
    "              'p': [1],\n",
    "              'algorithm': ['kd_tree'],\n",
    "              'leaf_size': [18],\n",
    "             }\n",
    "\n",
    "knn_grid = GridSearchCV(knn, param_grid = knn_params, cv=5, verbose=1, n_jobs=-1)\n",
    "knn_grid.fit(X_train, Y_train)\n",
    "print(knn_grid.best_params_)\n",
    "print(knn_grid.best_score_)\n",
    "print(knn_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='forest'></a>\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.9min remaining:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 40, 'max_features': 'log2', 'max_leaf_nodes': 200, 'min_impurity_decrease': 0, 'min_samples_leaf': 4, 'min_samples_split': 500, 'min_weight_fraction_leaf': 0, 'n_estimators': 1000}\n",
      "0.759453985835\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=40, max_features='log2', max_leaf_nodes=200,\n",
      "            min_impurity_decrease=0, min_impurity_split=None,\n",
      "            min_samples_leaf=4, min_samples_split=500,\n",
      "            min_weight_fraction_leaf=0, n_estimators=1000, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc_params = {\n",
    "              'n_estimators': [1000],\n",
    "              'max_features': ['log2'],\n",
    "              'min_samples_split': [500], \n",
    "              'max_depth': [40],\n",
    "              'min_samples_leaf': [4],\n",
    "              'min_weight_fraction_leaf': [0], \n",
    "              'max_leaf_nodes': [200],\n",
    "              'min_impurity_decrease': [0]\n",
    "             }\n",
    "\n",
    "rfr_grid = GridSearchCV(rfc, param_grid = rfc_params, cv=5, verbose=1, n_jobs=-1)\n",
    "rfr_grid.fit(X_train, Y_train)\n",
    "print(rfr_grid.best_params_)\n",
    "print(rfr_grid.best_score_)\n",
    "print(rfr_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='extra'></a>\n",
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  3.5min remaining:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 40, 'max_features': 'log2', 'max_leaf_nodes': 200, 'min_impurity_decrease': 0, 'min_samples_leaf': 4, 'min_samples_split': 500, 'min_weight_fraction_leaf': 0, 'n_estimators': 1000}\n",
      "0.759259471149\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=40, max_features='log2', max_leaf_nodes=200,\n",
      "           min_impurity_decrease=0, min_impurity_split=None,\n",
      "           min_samples_leaf=4, min_samples_split=500,\n",
      "           min_weight_fraction_leaf=0, n_estimators=1000, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "etrees = ExtraTreesClassifier()\n",
    "etrees_params = {\n",
    "              'n_estimators': [1000],\n",
    "              'max_features': ['log2'],\n",
    "              'min_samples_split': [500], \n",
    "              'max_depth': [40],\n",
    "              'min_samples_leaf': [4],\n",
    "              'min_weight_fraction_leaf': [0], \n",
    "              'max_leaf_nodes': [200],\n",
    "              'min_impurity_decrease': [0]\n",
    "             }\n",
    "\n",
    "etrees_grid = GridSearchCV(etrees, param_grid = etrees_params, cv=5, verbose=1, n_jobs=-1)\n",
    "etrees_grid.fit(X_train, Y_train)\n",
    "print(etrees_grid.best_params_)\n",
    "print(etrees_grid.best_score_)\n",
    "print(etrees_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm'></a>\n",
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   28.5s remaining:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   29.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'intercept_scaling': 0.5, 'loss': 'hinge', 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "0.617366728835\n",
      "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=0.5, loss='hinge', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC()\n",
    "lsvc_params = {\n",
    "             'penalty': ['l2'], \n",
    "             'loss': ['hinge'],\n",
    "             'C': [0.1],\n",
    "             'multi_class': ['ovr'],\n",
    "             'intercept_scaling': [0.5]\n",
    "             }\n",
    "\n",
    "lsvc_grid = GridSearchCV(lsvc, param_grid = lsvc_params, cv=5, verbose=1, n_jobs=-1)\n",
    "lsvc_grid.fit(X_train, Y_train)\n",
    "print(lsvc_grid.best_params_)\n",
    "print(lsvc_grid.best_score_)\n",
    "print(lsvc_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gradboost'></a>\n",
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.6min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 16, 'min_impurity_decrease': 0.2, 'min_samples_leaf': 220, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 150, 'subsample': 1}\n",
      "0.763023902422\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=16,\n",
      "              min_impurity_decrease=0.2, min_impurity_split=None,\n",
      "              min_samples_leaf=220, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0, n_estimators=150, presort='auto',\n",
      "              random_state=None, subsample=1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc_params = {\n",
    "              'max_features': [None],\n",
    "              'loss': ['deviance'],\n",
    "              'n_estimators': [150],\n",
    "              'max_depth': [3],\n",
    "              'min_samples_leaf': [220],\n",
    "              'min_samples_split': [2],\n",
    "              'learning_rate': [0.1],\n",
    "              'criterion': ['friedman_mse'],\n",
    "              'min_weight_fraction_leaf': [0],\n",
    "              'subsample': [1],\n",
    "              'max_leaf_nodes': [16],\n",
    "              'min_impurity_decrease': [0.2],\n",
    "             }\n",
    "\n",
    "gbc_grid = GridSearchCV(gbc, param_grid = gbc_params, cv=5, verbose=1, n_jobs =-1)\n",
    "gbc_grid.fit(X_train, Y_train)\n",
    "print(gbc_grid.best_params_)\n",
    "print(gbc_grid.best_score_)\n",
    "print(gbc_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='xgboost'></a>\n",
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   19.6s remaining:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   21.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5, 'colsample_bylevel': 0.8, 'colsample_bytree': 0.7, 'gamma': 0.65, 'learning_rate': 0.1, 'max_delta_step': 1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 0.2, 'scale_pos_weight': 1, 'subsample': 0.7}\n",
      "0.763390047713\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.8,\n",
      "       colsample_bytree=0.7, gamma=0.65, learning_rate=0.1,\n",
      "       max_delta_step=1, max_depth=5, min_child_weight=3, missing=None,\n",
      "       n_estimators=100, n_jobs=1, nthread=None,\n",
      "       objective='binary:logistic', random_state=0, reg_alpha=0.1,\n",
      "       reg_lambda=0.2, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=0.7)\n"
     ]
    }
   ],
   "source": [
    "# This performs pretty well but the sklearn wrapper doesn't play nice with sparse matricies so won't be used.\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_params = {\n",
    "              'max_depth': [5],\n",
    "              'learning_rate': [.1],\n",
    "              'n_estimators': [100],\n",
    "              'gamma': [.65],\n",
    "              'min_child_weight': [3],\n",
    "              'max_delta_step': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'colsample_bylevel': [0.8],\n",
    "              'reg_alpha': [0.1],\n",
    "              'reg_lambda': [0.2],\n",
    "              'scale_pos_weight' : [1],\n",
    "              'base_score' : [0.5],\n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(xgb, param_grid = xgb_params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, Y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.8,\n",
       "       colsample_bytree=0.7, gamma=0.65, learning_rate=0.1,\n",
       "       max_delta_step=1, max_depth=5, min_child_weight=3, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=-1, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0.1, reg_lambda=0.2, scale_pos_weight=1,\n",
       "       seed=0, silent=True, subsample=0.7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(base_score=0.5, colsample_bylevel=0.8, colsample_bytree=0.7,\n",
    "                            gamma=0.65, learning_rate=0.1, max_delta_step=1, max_depth=5,\n",
    "                            min_child_weight=3, missing=None, n_estimators=100, nthread=-1,\n",
    "                            objective='binary:logistic', reg_alpha=0.1, reg_lambda=0.2,\n",
    "                            scale_pos_weight=1, seed=0, silent=True, subsample=0.7)\n",
    "\n",
    "xgb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lgbm'></a>\n",
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.8s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.3s finished\n",
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_freq': 0, 'bagging_seed': 95, 'feature_fraction': 1.0, 'feature_fraction_seed': 95, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'learning_rate': 0.1, 'max_depth': 6, 'min_data_in_leaf': 30, 'min_split_gain': 0, 'num_boost_round': 40, 'num_leaves': 35, 'num_threads': 4}\n",
      "0.763309953431\n",
      "LGBMClassifier(bagging_freq=0, bagging_seed=95, boosting_type='gbdt',\n",
      "        class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,\n",
      "        feature_fraction_seed=95, lambda_l1=0.0, lambda_l2=0.0,\n",
      "        learning_rate=0.1, max_depth=6, min_child_samples=20,\n",
      "        min_child_weight=0.001, min_data_in_leaf=30, min_split_gain=0,\n",
      "        n_estimators=100, n_jobs=-1, num_boost_round=40, num_leaves=35,\n",
      "        num_threads=4, objective=None, random_state=None, reg_alpha=0.0,\n",
      "        reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "        subsample_for_bin=200000, subsample_freq=1)\n"
     ]
    }
   ],
   "source": [
    "lgbm = lgb.LGBMClassifier()\n",
    "lgbm_params = {\n",
    "               'num_boost_round': [40],\n",
    "               'learning_rate': [0.1],\n",
    "               'num_leaves': [35],\n",
    "               'num_threads': [4],\n",
    "               'max_depth': [6],\n",
    "               'min_data_in_leaf': [30],\n",
    "               'feature_fraction': [1.0],\n",
    "               'feature_fraction_seed': [95],\n",
    "               'bagging_freq': [0],\n",
    "               'bagging_seed': [95],\n",
    "               'lambda_l1': [0.0],\n",
    "               'lambda_l2': [0.0],\n",
    "               'min_split_gain': [0],\n",
    "             }\n",
    "\n",
    "lgbm_grid = GridSearchCV(lgbm, param_grid = lgbm_params, cv=5, n_jobs=-1, verbose=1)\n",
    "lgbm_grid.fit(X_train, Y_train)\n",
    "print(lgbm_grid.best_params_)\n",
    "print(lgbm_grid.best_score_)\n",
    "print(lgbm_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nn'></a>\n",
    "### Keras/Tensorflow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1297: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 87397 samples, validate on 29133 samples\n",
      "Epoch 1/20\n",
      "68992/87397 [======================>.......] - ETA: 3s - loss: 0.4992 - acc: 0.7522"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-504-b913dbeac954>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1507\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2269\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2270\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_k = Sequential()\n",
    "model_k.add(Dense(34, input_dim=Xtrain.shape[1], activation='relu'))\n",
    "model_k.add(Dense(34, activation='relu'))\n",
    "model_k.add(Dense(34, activation='relu'))\n",
    "model_k.add(Dense(34, activation='relu'))\n",
    "model_k.add(Dense(34, activation='relu'))\n",
    "model_k.add(Dense(17, activation='relu'))\n",
    "model_k.add(Dense(17, activation='relu'))\n",
    "model_k.add(Dense(17, activation='relu'))\n",
    "model_k.add(Dense(17, activation='relu'))\n",
    "model_k.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_k.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_k.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ensemble'></a>\n",
    "## Ensembling Our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = CalibratedClassifierCV(base_estimator=gbc_grid.best_estimator_, cv=5)\n",
    "model2 = CalibratedClassifierCV(base_estimator=rfr_grid.best_estimator_, cv=5)\n",
    "model3 = CalibratedClassifierCV(base_estimator=etrees_grid.best_estimator_, cv=5)\n",
    "model4 = CalibratedClassifierCV(base_estimator=knn_grid.best_estimator_, cv=5)\n",
    "model5 = CalibratedClassifierCV(base_estimator=lsvc_grid.best_estimator_, cv=5)\n",
    "model6 = CalibratedClassifierCV(base_estimator=lgbm_grid.best_estimator_, cv=5)\n",
    "\n",
    "clf1 = gbc_grid.best_estimator_\n",
    "clf2 = rfr_grid.best_estimator_\n",
    "clf3 = etrees_grid.best_estimator_\n",
    "clf4 = knn_grid.best_estimator_\n",
    "clf5 = lsvc_grid.best_estimator_\n",
    "clf6 = lgbm_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_model = VotingClassifier(estimators=[('gbc', model1), ('rfr', model2), ('etrees', model3), ('knn', model4), \n",
    "                                                ('lsvc', model5), ('lgbm', clf6), ('log', log)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hard = VotingClassifier(estimators=[('gbc', clf1), ('rfr', clf2), ('etrees', clf3), ('knn', clf4), \n",
    "                                          ('lsvc', clf5), ('lgbm', clf6), ('log', log)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_soft = VotingClassifier(estimators=[('gbc', clf1), ('rfr', clf2), ('etrees', clf3), ('knn', clf4), \n",
    "                                          ('lgbm', clf6), ('log', log)], voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exporting'></a>\n",
    "## Exporting Our Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brice\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #0. Accuracy = 0.762262726118\n",
      "The average accuracy is 0.762262726118\n"
     ]
    }
   ],
   "source": [
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Conference Champ','Tourney Conference Champ',\n",
    "            'Seed','SOS','SRS', 'RPG', 'SPG', 'Tourney Appearances','National Championships','Location', 'Team Season Elo']\n",
    "\n",
    "accuracy=[]\n",
    "numTrials = 1\n",
    "\n",
    "for i in range(numTrials):\n",
    "    results = model_soft.fit(X_train, Y_train)\n",
    "    preds = model_soft.predict(X_test)\n",
    "\n",
    "#    preds[preds < .5] = 0\n",
    "#    preds[preds >= .5] = 1\n",
    "    localAccuracy = np.mean(preds == Y_test)\n",
    "    accuracy.append(localAccuracy)\n",
    "    print (\"Finished run #\" + str(i) + \". Accuracy = \" + str(localAccuracy))\n",
    "print (\"The average accuracy is\", sum(accuracy)/len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictGame(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "\n",
    "    #return model_hard.predict([diff])[0]\n",
    "    return model_soft.predict_proba([diff])[0][1] # Depends on model(s) chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTeamVectors(years):\n",
    "    listDictionaries = []\n",
    "    for year in years:\n",
    "        curVectors = np.load(\"Data/PrecomputedMatrices/TeamVectors/\" + str(year) + \"TeamVectors.npy\").item()\n",
    "        listDictionaries.append(curVectors)\n",
    "    return listDictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPrediction():\n",
    "    if os.path.exists(\"results.csv\"):\n",
    "        os.remove(\"results.csv\")\n",
    "    years = range(2014,2018)\n",
    "    listDictionaries = loadTeamVectors(years)\n",
    "    print (\"Loaded the team vectors.\")\n",
    "    results = [[0 for x in range(2)] for x in range(len(sample_sub_pd.index))]\n",
    "    for index, row in sample_sub_pd.iterrows():\n",
    "        matchupId = row['ID']\n",
    "        year = int(matchupId[0:4]) \n",
    "        teamVectors = listDictionaries[year - years[0]]\n",
    "        team1Id = int(matchupId[5:9])\n",
    "        team2Id = int(matchupId[10:14])\n",
    "        team1Vector = teamVectors[team1Id] \n",
    "        team2Vector = teamVectors[team2Id]\n",
    "        pred = predictGame(team1Vector, team2Vector, 0)\n",
    "        results[index][0] = matchupId\n",
    "        results[index][1] = pred\n",
    "    results = pd.np.array(results)\n",
    "    firstRow = [[0 for x in range(2)] for x in range(1)]\n",
    "    firstRow[0][0] = 'ID'\n",
    "    firstRow[0][1] = 'Pred'\n",
    "    with open(\"result.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(firstRow)\n",
    "        writer.writerows(results)\n",
    "        print(\"Saved Results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the team vectors.\n",
      "Saved Results.\n"
     ]
    }
   ],
   "source": [
    "createPrediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014_1107_1110</td>\n",
       "      <td>0.441945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014_1107_1112</td>\n",
       "      <td>0.040672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014_1107_1113</td>\n",
       "      <td>0.136355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014_1107_1124</td>\n",
       "      <td>0.055960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014_1107_1140</td>\n",
       "      <td>0.168766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014_1107_1142</td>\n",
       "      <td>0.576289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014_1107_1153</td>\n",
       "      <td>0.102997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014_1107_1157</td>\n",
       "      <td>0.584205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014_1107_1160</td>\n",
       "      <td>0.184427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014_1107_1163</td>\n",
       "      <td>0.055720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014_1107_1166</td>\n",
       "      <td>0.074484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014_1107_1173</td>\n",
       "      <td>0.122786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014_1107_1174</td>\n",
       "      <td>0.286943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014_1107_1181</td>\n",
       "      <td>0.073918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014_1107_1184</td>\n",
       "      <td>0.355571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014_1107_1196</td>\n",
       "      <td>0.034621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014_1107_1203</td>\n",
       "      <td>0.171980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014_1107_1211</td>\n",
       "      <td>0.072832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014_1107_1217</td>\n",
       "      <td>0.147440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014_1107_1234</td>\n",
       "      <td>0.117651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014_1107_1235</td>\n",
       "      <td>0.054676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014_1107_1242</td>\n",
       "      <td>0.045758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014_1107_1243</td>\n",
       "      <td>0.136185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014_1107_1246</td>\n",
       "      <td>0.054358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014_1107_1257</td>\n",
       "      <td>0.040787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2014_1107_1264</td>\n",
       "      <td>0.266977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2014_1107_1269</td>\n",
       "      <td>0.304918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2014_1107_1272</td>\n",
       "      <td>0.109445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2014_1107_1273</td>\n",
       "      <td>0.250880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2014_1107_1276</td>\n",
       "      <td>0.053855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9082</th>\n",
       "      <td>2017_1437_1458</td>\n",
       "      <td>0.721004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9083</th>\n",
       "      <td>2017_1437_1462</td>\n",
       "      <td>0.817213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9084</th>\n",
       "      <td>2017_1438_1439</td>\n",
       "      <td>0.631656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>2017_1438_1448</td>\n",
       "      <td>0.665232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9086</th>\n",
       "      <td>2017_1438_1452</td>\n",
       "      <td>0.361944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>2017_1438_1455</td>\n",
       "      <td>0.455836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>2017_1438_1457</td>\n",
       "      <td>0.869304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>2017_1438_1458</td>\n",
       "      <td>0.507641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>2017_1438_1462</td>\n",
       "      <td>0.608186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>2017_1439_1448</td>\n",
       "      <td>0.557523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>2017_1439_1452</td>\n",
       "      <td>0.251494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9093</th>\n",
       "      <td>2017_1439_1455</td>\n",
       "      <td>0.333984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9094</th>\n",
       "      <td>2017_1439_1457</td>\n",
       "      <td>0.787086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9095</th>\n",
       "      <td>2017_1439_1458</td>\n",
       "      <td>0.308913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096</th>\n",
       "      <td>2017_1439_1462</td>\n",
       "      <td>0.432084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9097</th>\n",
       "      <td>2017_1448_1452</td>\n",
       "      <td>0.283734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9098</th>\n",
       "      <td>2017_1448_1455</td>\n",
       "      <td>0.345879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9099</th>\n",
       "      <td>2017_1448_1457</td>\n",
       "      <td>0.787763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9100</th>\n",
       "      <td>2017_1448_1458</td>\n",
       "      <td>0.313511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9101</th>\n",
       "      <td>2017_1448_1462</td>\n",
       "      <td>0.372081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>2017_1452_1455</td>\n",
       "      <td>0.596079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>2017_1452_1457</td>\n",
       "      <td>0.923324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9104</th>\n",
       "      <td>2017_1452_1458</td>\n",
       "      <td>0.614398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>2017_1452_1462</td>\n",
       "      <td>0.730301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>2017_1455_1457</td>\n",
       "      <td>0.908167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9107</th>\n",
       "      <td>2017_1455_1458</td>\n",
       "      <td>0.501862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9108</th>\n",
       "      <td>2017_1455_1462</td>\n",
       "      <td>0.642148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9109</th>\n",
       "      <td>2017_1457_1458</td>\n",
       "      <td>0.087142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9110</th>\n",
       "      <td>2017_1457_1462</td>\n",
       "      <td>0.153112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9111</th>\n",
       "      <td>2017_1458_1462</td>\n",
       "      <td>0.592594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9112 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID      Pred\n",
       "0     2014_1107_1110  0.441945\n",
       "1     2014_1107_1112  0.040672\n",
       "2     2014_1107_1113  0.136355\n",
       "3     2014_1107_1124  0.055960\n",
       "4     2014_1107_1140  0.168766\n",
       "5     2014_1107_1142  0.576289\n",
       "6     2014_1107_1153  0.102997\n",
       "7     2014_1107_1157  0.584205\n",
       "8     2014_1107_1160  0.184427\n",
       "9     2014_1107_1163  0.055720\n",
       "10    2014_1107_1166  0.074484\n",
       "11    2014_1107_1173  0.122786\n",
       "12    2014_1107_1174  0.286943\n",
       "13    2014_1107_1181  0.073918\n",
       "14    2014_1107_1184  0.355571\n",
       "15    2014_1107_1196  0.034621\n",
       "16    2014_1107_1203  0.171980\n",
       "17    2014_1107_1211  0.072832\n",
       "18    2014_1107_1217  0.147440\n",
       "19    2014_1107_1234  0.117651\n",
       "20    2014_1107_1235  0.054676\n",
       "21    2014_1107_1242  0.045758\n",
       "22    2014_1107_1243  0.136185\n",
       "23    2014_1107_1246  0.054358\n",
       "24    2014_1107_1257  0.040787\n",
       "25    2014_1107_1264  0.266977\n",
       "26    2014_1107_1269  0.304918\n",
       "27    2014_1107_1272  0.109445\n",
       "28    2014_1107_1273  0.250880\n",
       "29    2014_1107_1276  0.053855\n",
       "...              ...       ...\n",
       "9082  2017_1437_1458  0.721004\n",
       "9083  2017_1437_1462  0.817213\n",
       "9084  2017_1438_1439  0.631656\n",
       "9085  2017_1438_1448  0.665232\n",
       "9086  2017_1438_1452  0.361944\n",
       "9087  2017_1438_1455  0.455836\n",
       "9088  2017_1438_1457  0.869304\n",
       "9089  2017_1438_1458  0.507641\n",
       "9090  2017_1438_1462  0.608186\n",
       "9091  2017_1439_1448  0.557523\n",
       "9092  2017_1439_1452  0.251494\n",
       "9093  2017_1439_1455  0.333984\n",
       "9094  2017_1439_1457  0.787086\n",
       "9095  2017_1439_1458  0.308913\n",
       "9096  2017_1439_1462  0.432084\n",
       "9097  2017_1448_1452  0.283734\n",
       "9098  2017_1448_1455  0.345879\n",
       "9099  2017_1448_1457  0.787763\n",
       "9100  2017_1448_1458  0.313511\n",
       "9101  2017_1448_1462  0.372081\n",
       "9102  2017_1452_1455  0.596079\n",
       "9103  2017_1452_1457  0.923324\n",
       "9104  2017_1452_1458  0.614398\n",
       "9105  2017_1452_1462  0.730301\n",
       "9106  2017_1455_1457  0.908167\n",
       "9107  2017_1455_1458  0.501862\n",
       "9108  2017_1455_1462  0.642148\n",
       "9109  2017_1457_1458  0.087142\n",
       "9110  2017_1457_1462  0.153112\n",
       "9111  2017_1458_1462  0.592594\n",
       "\n",
       "[9112 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('result.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bracketeer import build_bracket\n",
    "b = build_bracket(\n",
    "        output_path='output.png', \n",
    "        teamsPath='Data/KaggleData/Teams.csv',\n",
    "        seedsPath='Data/KaggleData/NCAATourneySeeds.csv',\n",
    "        submissionPath='result.csv',\n",
    "        slotsPath='Data/KaggleData/NCAATourneySlots.csv',\n",
    "        year=2018\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
